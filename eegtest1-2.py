# -*- coding: utf-8 -*-
"""EEGTest1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ktfB8jSwcC9zWioiXri5af9km3cirlD3

# Epileptic seizure detection using recurrent neural networks

## In this jupyter notebook the preictal and interictal data is separated 
Juan David Torres Velasco
A01702686
"""

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
drive.mount('/content/drive')

# %cd "/content/drive/My Drive/Tesina/20min"
!pwd

#Import the necessary libraries
import os 
import numpy as np
# import mne
import matplotlib.pyplot as plt
import os
import pandas as pd
import matplotlib.pyplot as plot
import re
from random import randint

"""## Constants"""

SIXTYSECONDS = 60
SAMPLE_PER_SECOND = 256

MINUTES_PREICTAL = 20

# CHANNELS = ['FP1-F7', 'F7-T7', 'T7-P7', 'P7-O1', 'FP1-F3', 'F3-C3', 'C3-P3', 'P3-O1', 'FP2-F4', 'F4-C4', 'C4-P4', 'P4-O2', 'FP2-F8', 'F8-T8', 'T8-P8-0', 'P8-O2', 'FZ-CZ', 'CZ-PZ', 'P7-T7', 'T7-FT9', 'FT9-FT10', 'FT10-T8']

# CHANNELS = ["FP1-F7","F7-T7","T7-P7","P7-O1","FP1-F3","F3-C3","C3-P3","P3-O1","FP2-F4","F4-C4","C4-P4","P4-O2","FP2-F8","F8-T8","T8-P8-0","P8-O2","FZ-CZ","CZ-PZ"]
CHANNELS = ['FP1-F7', 'F7-T7', 'T7-P7', 'P7-O1', 'FP1-F3', 'F3-C3', 'C3-P3', 'P3-O1', 'FP2-F4', 'F4-C4', 'C4-P4', 'P4-O2', 'FP2-F8', 'F8-T8', 'T8-P8-0', 'P8-O2', 'FZ-CZ', 'CZ-PZ', 'P7-T7', 'T7-FT9']
NUM_CHANNELS = len(CHANNELS)

REDUCED_PREICTAL_MINUTES = 2
TIMESTEP = 12
SECONDS_PER_TS = int(SIXTYSECONDS*REDUCED_PREICTAL_MINUTES/TIMESTEP)
SIZE_DATA = 2960
print("Length Channels", len(CHANNELS))

testpath = '/Volumes/Seagate Hard Drive/Tesina/chb-mit-scalp-eeg-database-1.0.0/chb01/chb01_15.edf'


raw = mne.io.read_raw_edf(testpath,verbose="ERROR")
d = raw.get_data(CHANNELS)
print(d.shape)
info = mne.create_info(ch_names=CHANNELS, sfreq=256, ch_types=['eeg']*d.shape[0] )

# create raw mne object
raw = mne.io.RawArray(d, info)
raw.set_annotations(mne.Annotations(onset=[1732,1772],duration=40,description=['seizure','']))
raw.plot(start=1728,color='b',)

replace_dict = {}
drop_list = []
# for the channel names in the data...
for channel_name in raw.info['ch_names']:
    # get the name to change too
    name_change = re.findall('\w+',channel_name)[0].title()
    # check if it is already in the change list
    if name_change in list(replace_dict.values()):
        drop_list.append(channel_name)
    else:
        # if its not already there get the origional name and what we want to 
        # change it to
        replace_dict[channel_name] = name_change

# drop the ones that would be repeats
raw.drop_channels(drop_list)
# rename the TESTchannels
raw.rename_channels(replace_dict)
# set the standard montage
raw.set_montage('standard_1020')

raw.plot_sensors(kind='topomap', show_names=True, to_sphere=True)
fig = raw.plot_sensors(kind='3d', show_names=True, show=False)
fig = fig.gca().view_init(azim=70, elev=15)
plot.show()

"""## Test the reading of the data"""

#this is the path where I stored the data for the CHB MIT dataset, replace accordingly, using EDF files
homepath = '/Volumes/Seagate Hard Drive/Tesina/chb-mit-scalp-eeg-database-1.0.0'
path_test = homepath + '/chb01' 
raw = mne.io.read_raw_edf(path_test + '/chb01_03.edf')
raw2 = mne.io.read_raw_edf(path_test + '/chb01_02.edf')
d = raw.get_data(CHANNELS)
d2 = raw2.get_data(CHANNELS)
print(d.shape)
print(d2.shape)

temppp = np.concatenate((d,d2), axis = 1)

print(temppp.shape)

"""## Initialize the structures that are going to be used"""

non_seizure_data = np.array([])
text_file = np.zeros(shape = (2,1))
total_arr_files_seizure = []

"""### Function to parse through the text file with the seizure information of the different .edf files"""

def parse_summary(text_file, home_path, minutes_preictal):
    file = open((home_path + '/' + text_file), 'r')
    Lines = file.readlines()
    seizures_count = 0
    i = 29
    array_seizure_start = []
    arrayEndTime = []
    seizure_list = []
    seizure_dict = {}
    total_records = 0
    file_names = []
    while i < len(Lines):
        print(i)
        file_name = Lines[i].split(": ",1)[1]
        file_name = file_name.replace(" ","")
        file_name = file_name.replace("\n","")
        file_names.append(file_name)

        number_seizures = int(Lines[i+3].split(": ",1)[1])

        array_seizure_start = []
        if number_seizures > 0:

            for j in range(number_seizures):
                print("Lines1",Lines[i+3+(j*2)+1].split(": ",1)[1])
                print("Lines2",Lines[i+3+(j*2)+2].split(": ",1)[1])
                start_of_seizure = Lines[i+3+(j*2)+2].split(": ",1)[1]
                start_of_seizure = start_of_seizure.replace(' seconds\n','')
                start_of_seizure = int(start_of_seizure)
                array_seizure_start.append(start_of_seizure)

            print("-",file_name,"-")
            raw = mne.io.read_raw_edf(home_path + '/' + file_name)
            print("CHANNELSS: ",CHANNELS)
            data = raw.get_data(CHANNELS)
            
            print("File name: ", file_name, " Shape ", data.shape)
            total_arr_files_seizure.append(file_name)

            for seizure_start in array_seizure_start:
                ictal_start = seizure_start * SAMPLE_PER_SECOND
                preictal_start = ictal_start - (SAMPLE_PER_SECOND * minutes_preictal * SIXTYSECONDS)
                # total_records += 
                print("Ictal start ",ictal_start,"Preictal start ",preictal_start, " Seconds:", seizure_start)
                if preictal_start >= 0:

                    if seizures_count == 0:
                        seizure_data_loc = data[:23,preictal_start:ictal_start]
                    else:
                        seizure_data_temp = np.concatenate((seizure_data_loc,data[:23,preictal_start:ictal_start]),axis=1)
                        seizure_data_loc = seizure_data_temp

                else:
                    
                    print("Preictal st",preictal_start)
                    raw_prev = mne.io.read_raw_edf(home_path + '/' + file_names[-1])
                    print("CHANNELSS: ",CHANNELS)
                    data_prev = raw_prev.get_data(CHANNELS)
                    print("SHAPEEEE ",len(data_prev[0]))
                    if seizures_count == 0:
                        
                        seizure_data_loc = data_prev[:23,(len(data_prev[0])+preictal_start):]
                        seizure_data_temp = np.concatenate((seizure_data_loc,data[:23,:ictal_start]),axis=1)
                        seizure_data_loc = seizure_data_temp
                        
                    else:

                        # if len(data_prev) < (-preictal_start):
                        #     print("------------------------------VERY SMALL DATA!!!!------------------------------")
                        #     break
                        seizure_data_temp = np.concatenate((seizure_data_loc,data_prev[:23,(len(data_prev[0])+preictal_start):]),axis=1)
                        seizure_data_loc = seizure_data_temp

                        seizure_data_temp = np.concatenate((seizure_data_loc,data[:23,:ictal_start]),axis=1)
                        seizure_data_loc = seizure_data_temp

                seizures_count += 1
            
            seizure_list.append({"file_name":file_name, "number_seizures":number_seizures})
            i += 2*number_seizures
            
        i += 5
    
    print(array_seizure_start)
    print(arrayEndTime)
    print("Seizure data shape",seizure_data_loc.shape)
    return seizure_data_loc

"""## Go through the different patients looking for the text file, parse throguh them and save the preictal data into a numpy darray"""

seizure_data = np.array([])
for i in range(1,25):
    if i <= 9:
            
            path = homepath + '/chb0' + str(i)
            
            files = os.listdir(path)
            for f in files:
                
                if  f.endswith('.txt'):
                    print("PATHH", path)
                    if i == 1:
                        seizure_data = parse_summary(f,path, MINUTES_PREICTAL)
                    else:
                        seizure_data_temporal = np.concatenate((seizure_data, parse_summary(f, path, MINUTES_PREICTAL)),axis=1)
                        seizure_data = seizure_data_temporal
                        
                    
                    print("Seizure data shape end",seizure_data.shape)
                    print(f)

        
        
    else:
        path = homepath + '/chb' + str(i)
        if  i!=24:
            # and i != 13 and i != 14
            files = os.listdir(path)
            for f in files:
                
                if f.endswith('.txt') :
                    print(f)
                    seizure_data_temporal = np.concatenate((seizure_data, parse_summary(f, path, MINUTES_PREICTAL)),axis=1)
                    seizure_data = seizure_data_temporal
                    print("Seizure data shape end",seizure_data.shape)
print(seizure_data.shape)  
print(total_arr_files_seizure)
np.save('/Volumes/Seagate Hard Drive/Tesina/preictal2', seizure_data, allow_pickle=True, fix_imports=False)

"""## Interictal

"""

# seizure_data = np.load('preictal.npy', mmap_mode=None, allow_pickle=True, fix_imports=False)
print(seizure_data.shape)
# total_arr_files_seizure = ['chb01_03.edf', 'chb01_04.edf', 'chb01_15.edf', 'chb01_16.edf', 'chb01_18.edf', 'chb01_21.edf', 'chb01_26.edf', 'chb02_16.edf', 'chb01_03.edf', 'chb01_04.edf', 'chb01_15.edf', 'chb01_16.edf', 'chb01_18.edf', 'chb01_21.edf', 'chb01_26.edf', 'chb02_16.edf', 'chb02_16+.edf', 'chb02_19.edf', 'chb03_01.edf', 'chb03_02.edf', 'chb03_03.edf', 'chb03_04.edf', 'chb03_34.edf', 'chb03_35.edf', 'chb03_36.edf', 'chb04_05.edf', 'chb04_08.edf', 'chb04_28.edf', 'chb05_06.edf', 'chb05_13.edf', 'chb05_16.edf', 'chb05_17.edf', 'chb05_22.edf', 'chb06_01.edf', 'chb06_04.edf', 'chb06_09.edf', 'chb06_10.edf', 'chb06_13.edf', 'chb06_18.edf', 'chb06_24.edf', 'chb07_12.edf', 'chb07_13.edf', 'chb07_19.edf', 'chb08_02.edf', 'chb08_05.edf', 'chb08_11.edf', 'chb08_13.edf', 'chb08_21.edf', 'chb09_06.edf', 'chb09_08.edf', 'chb09_19.edf', 'chb10_12.edf', 'chb10_20.edf', 'chb10_27.edf', 'chb10_30.edf', 'chb10_31.edf', 'chb10_38.edf', 'chb10_89.edf', 'chb11_82.edf', 'chb11_92.edf', 'chb11_99.edf', 'chb13_19.edf', 'chb13_21.edf', 'chb15_06.edf', 'chb15_10.edf', 'chb15_15.edf', 'chb15_17.edf', 'chb15_20.edf', 'chb15_22.edf', 'chb15_28.edf', 'chb15_31.edf', 'chb15_40.edf', 'chb15_46.edf', 'chb15_49.edf', 'chb15_52.edf', 'chb15_54.edf', 'chb15_62.edf', 'chb16_10.edf', 'chb16_11.edf', 'chb16_14.edf', 'chb16_16.edf', 'chb17a_03.edf', 'chb17a_04.edf', 'chb17b_63.edf', 'chb18_29.edf', 'chb18_30.edf', 'chb18_31.edf', 'chb18_32.edf', 'chb18_35.edf', 'chb18_36.edf', 'chb19_28.edf', 'chb19_29.edf', 'chb19_30.edf', 'chb20_12.edf', 'chb20_13.edf', 'chb20_14.edf', 'chb20_15.edf', 'chb20_16.edf', 'chb20_68.edf', 'chb21_19.edf', 'chb21_20.edf', 'chb21_21.edf', 'chb21_22.edf', 'chb22_20.edf', 'chb22_25.edf', 'chb22_38.edf', 'chb23_06.edf', 'chb23_08.edf', 'chb23_09.edf']

"""## Go through the files that weren't used for the preictal data and use them for the interictal"""

interictal_instance = len(seizure_data[0])/(MINUTES_PREICTAL*SIXTYSECONDS*SAMPLE_PER_SECOND)
interictal_data = np.array([])
j = 0
print("Instances",interictal_instance)
print()

for i in range(1,25):
    if j < interictal_instance:
        if i <= 9:
                path = homepath + '/chb0' + str(i)
            
                
                files = os.listdir(path)
                for f in files:
                    if j<interictal_instance:
                        if  not f.endswith('.txt') and not f.endswith('.seizures') and f not in total_arr_files_seizure :
                            print("PATHH", path)
                            print("file: ",f)
                            raw = mne.io.read_raw_edf(path + '/' + f)
                            data = raw.get_data(CHANNELS)
                            print("instances",MINUTES_PREICTAL*SIXTYSECONDS*SAMPLE_PER_SECOND)
                            print("Total of instances", len(data[0]))
                            if (MINUTES_PREICTAL*SIXTYSECONDS*SAMPLE_PER_SECOND)>len(data[0]):
                                print("THE DATA IS SMALLER!")
                                break
                                break
                            if j == 0:
                                interictal_data = data[:23,:(MINUTES_PREICTAL*SIXTYSECONDS*SAMPLE_PER_SECOND)]
                            else:
                                interictal_data_temporal = np.concatenate((interictal_data, data[:23,:(MINUTES_PREICTAL*SIXTYSECONDS*SAMPLE_PER_SECOND)]),axis=1)
                                interictal_data = interictal_data_temporal
                            
                            j+=1
                            print("Seizure data shape end",interictal_data.shape)
                            print(f)
                    else:
                        break
            
            
        else:
            path = homepath + '/chb' + str(i)
            if True:
                # and i != 13 and i != 14
                files = os.listdir(path)
                for f in files:
                    if j < interictal_instance:
                        if  not f.endswith('.txt') and not f.endswith('.seizures') and f not in total_arr_files_seizure :
                            print("PATHH", path)
                            raw = mne.io.read_raw_edf(path + '/' + f)
                            data = raw.get_data(CHANNELS)
                            interictal_data_temporal = np.concatenate((interictal_data, data[:23,:(MINUTES_PREICTAL*SIXTYSECONDS*SAMPLE_PER_SECOND)]),axis=1)
                            interictal_data = interictal_data_temporal
                            
                            j+=1
                            print("Seizure data shape end",interictal_data.shape)
                            print(f)
                    else:
                        break
    else:
        break

np.save('/Volumes/Seagate Hard Drive/Tesina/interictal2', interictal_data, allow_pickle=True, fix_imports=False)

seizure_data = np.load('/Volumes/Seagate Hard Drive/Tesina/preictal2.npy', mmap_mode=None, allow_pickle=True, fix_imports=False)
interictal_data = np.load('/Volumes/Seagate Hard Drive/Tesina/interictal2.npy', mmap_mode=None, allow_pickle=True, fix_imports=False)
print(interictal_data.shape)
print(seizure_data.shape)
# preictal = seizure_data[:,:SAMPLE_PER_SECOND*MINUTES_PREICTAL*SIZE_DATA*SIXTYSECONDS]
# interictal = interictal_data[:,:SAMPLE_PER_SECOND*MINUTES_PREICTAL*SIZE_DATA*SIXTYSECONDS]

preictal = seizure_data[:,:SAMPLE_PER_SECOND*SIXTYSECONDS*MINUTES_PREICTAL*148]
interictal = interictal_data[:,:SAMPLE_PER_SECOND*SIXTYSECONDS*MINUTES_PREICTAL*148]
print(preictal.shape)
print(interictal.shape)

"""## Reshaping Preictal"""

temp_preictal = preictal.reshape(NUM_CHANNELS,-1,SAMPLE_PER_SECOND*SIXTYSECONDS*REDUCED_PREICTAL_MINUTES)
print(temp_preictal.shape)
print(temp_preictal[17,0,:10])

# temp2_pr
temp_preictal = temp_preictal.transpose(1,0,2)
print(temp_preictal.shape)
print(TIMESTEP,SECONDS_PER_TS)
temp_preictal = temp_preictal.reshape(-1,TIMESTEP,NUM_CHANNELS*SECONDS_PER_TS*SAMPLE_PER_SECOND)

print(temp_preictal.shape)

"""## Reshaping Interictal"""

print(interictal.shape)
print(interictal[0,:10])
temp_interictal = interictal.reshape(NUM_CHANNELS,-1,SAMPLE_PER_SECOND*SIXTYSECONDS*REDUCED_PREICTAL_MINUTES)
print(temp_interictal.shape)
print(temp_interictal[0,0,:10])

# temp2_pr
temp_interictal = temp_interictal.transpose(1,0,2)
print(temp_interictal[0,0,:10])
temp_interictal = temp_interictal.reshape(-1,TIMESTEP,NUM_CHANNELS*SECONDS_PER_TS*SAMPLE_PER_SECOND)

print(temp_interictal.shape)

"""## Create Classes"""

class_preictal = np.full(int(SIZE_DATA/2),1)
class_interictal = np.full(int(SIZE_DATA/2),0)
print(class_preictal.shape)
print(class_interictal.shape)
classes = np.append(class_preictal,class_interictal)
print(classes.shape)
print(classes)
data = np.concatenate((temp_preictal,temp_interictal),axis=0)
print(data.shape)

"""## Shuffling"""

indexes = np.arange(0,2960,1)
print(indexes)

np.random.shuffle(indexes)
print(indexes)

new_classes = classes[indexes]
new_data = data[indexes]

print( new_classes.shape)
print(new_classes)

new_data = data[indexes]
print(new_data.shape)

"""## Shuffle"""

# new_data = np.array([])
# new_classes = np.array([])
# randomIndexes = []
# for i in range(len(data)):

#     randomIndex = randint(0,len(data)-1)
#     while randomIndex in randomIndexes:
#         randomIndex = randint(0,len(data)-1)
#     randomIndexes.append(randomIndex)
#     if i == 0:
#         new_data = data[randomIndex,:,:]
#         new_classes = classes[randomIndex]
#     else:
#         temp_new_data = np.concatenate((new_data, data[randomIndex,:,:]), axis= 1)
#         temp_new_classes = np.append(new_classes, classes[randomIndex])

#         new_data = temp_new_data
#         new_classes = temp_new_classes 
    
# print(new_classes)
# new_data = new_data.reshape(-1,TIMESTEP,NUM_CHANNELS*SECONDS_PER_TS*SAMPLE_PER_SECOND)

"""## Data splitting"""

x_Val = new_data[: 148,:,:]
y_Val = new_classes[:148]

x_Test = new_data[148 : 296,:,:]
y_Test = new_classes[148:296]

x_Train = new_data[296:,:,:]
y_Train = new_classes[296:]

print(x_Train.shape, y_Train.shape)
print(x_Val.shape, y_Val.shape)
print(x_Test.shape, y_Test.shape)

"""## Export Data"""

np.save('/Volumes/Seagate Hard Drive/Tesina/x_Train', x_Train, allow_pickle=True, fix_imports=False)
np.save('/Volumes/Seagate Hard Drive/Tesina/y_Train', y_Train, allow_pickle=True, fix_imports=False)
np.save('/Volumes/Seagate Hard Drive/Tesina/x_Val', x_Val, allow_pickle=True, fix_imports=False)
np.save('/Volumes/Seagate Hard Drive/Tesina/y_Val', y_Val, allow_pickle=True, fix_imports=False)
np.save('/Volumes/Seagate Hard Drive/Tesina/x_Test', x_Test, allow_pickle=True, fix_imports=False)
np.save('/Volumes/Seagate Hard Drive/Tesina/y_Test', y_Test, allow_pickle=True, fix_imports=False)

